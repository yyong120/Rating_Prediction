{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_set.csv'\n",
    "valid_file = 'valid_set.csv'\n",
    "seen_test_file = 'seen_test_set.csv'\n",
    "unseen_test_file = 'unseen_test_set.csv'\n",
    "test_file = 'test_set.csv'\n",
    "\n",
    "def get_all_data(file_name):\n",
    "    df = pd.read_csv(file_name, sep=',')\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # iterate through the whole dataset\n",
    "    for _, row in df.iterrows():\n",
    "        user_avg_rating = row['user_avg_rating']\n",
    "        item_avg_rating = row['item_avg_rating']\n",
    "        rating = row['rating']\n",
    "\n",
    "        size = int(row['size_idx'])\n",
    "        fit = int(row['fit_idx'])\n",
    "        user_attr = int(row['user_attr_idx'])\n",
    "        model_attr = int(row['model_attr_idx'])\n",
    "        category = int(row['category_idx'])\n",
    "        brand = int(row['brand_idx'])\n",
    "        year = int(row['year_idx'])\n",
    "        split = int(row['split_idx'])\n",
    "\n",
    "        features.append([user_avg_rating, item_avg_rating,\n",
    "                        size, fit,\n",
    "                        user_attr, model_attr,\n",
    "                        category, brand,\n",
    "                        year, split])\n",
    "        \n",
    "        labels.append(rating)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "X_train, y_train = get_all_data(train_file)\n",
    "X_valid, y_valid = get_all_data(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84811 10\n",
      "4547 10\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_train[0]))\n",
    "print(len(X_valid), len(X_valid[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into DMatrix format, which is optimized for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# define the evaluation sets: training and validation sets\n",
    "evals = [(dtrain, 'train'), (dvalid, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable parameters of XGBoost\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # For regression tasks\n",
    "    'eval_metric': 'rmse',  # Use RMSE as evaluation metric\n",
    "    'eta': 0.1,  # Learning rate\n",
    "    'max_depth': 6,  # Maximum depth of trees\n",
    "    'subsample': 0.8,  # Subsampling ratio\n",
    "    'colsample_bytree': 0.8  # Column sampling ratio\n",
    "}\n",
    "\n",
    "num_round = 1000  # Max number of boosting rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.01505\teval-rmse:1.06769\n",
      "[1]\ttrain-rmse:0.95868\teval-rmse:1.05005\n",
      "[2]\ttrain-rmse:0.91247\teval-rmse:1.03925\n",
      "[3]\ttrain-rmse:0.87058\teval-rmse:1.02642\n",
      "[4]\ttrain-rmse:0.83423\teval-rmse:1.01391\n",
      "[5]\ttrain-rmse:0.80751\teval-rmse:1.01068\n",
      "[6]\ttrain-rmse:0.79451\teval-rmse:0.99930\n",
      "[7]\ttrain-rmse:0.76930\teval-rmse:0.99002\n",
      "[8]\ttrain-rmse:0.74837\teval-rmse:0.98292\n",
      "[9]\ttrain-rmse:0.74041\teval-rmse:0.97572\n",
      "[10]\ttrain-rmse:0.73796\teval-rmse:0.97350\n",
      "[11]\ttrain-rmse:0.73595\teval-rmse:0.97146\n",
      "[12]\ttrain-rmse:0.72115\teval-rmse:0.96834\n",
      "[13]\ttrain-rmse:0.70877\teval-rmse:0.96582\n",
      "[14]\ttrain-rmse:0.69714\teval-rmse:0.96117\n",
      "[15]\ttrain-rmse:0.68763\teval-rmse:0.95775\n",
      "[16]\ttrain-rmse:0.68056\teval-rmse:0.95622\n",
      "[17]\ttrain-rmse:0.67387\teval-rmse:0.95340\n",
      "[18]\ttrain-rmse:0.66815\teval-rmse:0.95015\n",
      "[19]\ttrain-rmse:0.66358\teval-rmse:0.94819\n",
      "[20]\ttrain-rmse:0.66167\teval-rmse:0.94621\n",
      "[21]\ttrain-rmse:0.65794\teval-rmse:0.94467\n",
      "[22]\ttrain-rmse:0.65486\teval-rmse:0.94307\n",
      "[23]\ttrain-rmse:0.65222\teval-rmse:0.94169\n",
      "[24]\ttrain-rmse:0.65120\teval-rmse:0.94024\n",
      "[25]\ttrain-rmse:0.64912\teval-rmse:0.93942\n",
      "[26]\ttrain-rmse:0.64753\teval-rmse:0.93881\n",
      "[27]\ttrain-rmse:0.64623\teval-rmse:0.93841\n",
      "[28]\ttrain-rmse:0.64518\teval-rmse:0.93812\n",
      "[29]\ttrain-rmse:0.64387\teval-rmse:0.93709\n",
      "[30]\ttrain-rmse:0.64287\teval-rmse:0.93642\n",
      "[31]\ttrain-rmse:0.64212\teval-rmse:0.93622\n",
      "[32]\ttrain-rmse:0.64154\teval-rmse:0.93618\n",
      "[33]\ttrain-rmse:0.64084\teval-rmse:0.93555\n",
      "[34]\ttrain-rmse:0.64023\teval-rmse:0.93518\n",
      "[35]\ttrain-rmse:0.63966\teval-rmse:0.93478\n",
      "[36]\ttrain-rmse:0.63911\teval-rmse:0.93440\n",
      "[37]\ttrain-rmse:0.63873\teval-rmse:0.93435\n",
      "[38]\ttrain-rmse:0.63838\teval-rmse:0.93410\n",
      "[39]\ttrain-rmse:0.63815\teval-rmse:0.93405\n",
      "[40]\ttrain-rmse:0.63777\teval-rmse:0.93385\n",
      "[41]\ttrain-rmse:0.63743\teval-rmse:0.93358\n",
      "[42]\ttrain-rmse:0.63719\teval-rmse:0.93354\n",
      "[43]\ttrain-rmse:0.63683\teval-rmse:0.93333\n",
      "[44]\ttrain-rmse:0.63643\teval-rmse:0.93300\n",
      "[45]\ttrain-rmse:0.63615\teval-rmse:0.93290\n",
      "[46]\ttrain-rmse:0.63578\teval-rmse:0.93276\n",
      "[47]\ttrain-rmse:0.63556\teval-rmse:0.93248\n",
      "[48]\ttrain-rmse:0.63511\teval-rmse:0.93224\n",
      "[49]\ttrain-rmse:0.63493\teval-rmse:0.93223\n",
      "[50]\ttrain-rmse:0.63472\teval-rmse:0.93204\n",
      "[51]\ttrain-rmse:0.63456\teval-rmse:0.93198\n",
      "[52]\ttrain-rmse:0.63438\teval-rmse:0.93197\n",
      "[53]\ttrain-rmse:0.63404\teval-rmse:0.93155\n",
      "[54]\ttrain-rmse:0.63376\teval-rmse:0.93151\n",
      "[55]\ttrain-rmse:0.63363\teval-rmse:0.93147\n",
      "[56]\ttrain-rmse:0.63342\teval-rmse:0.93130\n",
      "[57]\ttrain-rmse:0.63322\teval-rmse:0.93123\n",
      "[58]\ttrain-rmse:0.63300\teval-rmse:0.93125\n",
      "[59]\ttrain-rmse:0.63273\teval-rmse:0.93118\n",
      "[60]\ttrain-rmse:0.63250\teval-rmse:0.93132\n",
      "[61]\ttrain-rmse:0.63221\teval-rmse:0.93133\n",
      "[62]\ttrain-rmse:0.63206\teval-rmse:0.93123\n",
      "[63]\ttrain-rmse:0.63187\teval-rmse:0.93102\n",
      "[64]\ttrain-rmse:0.63159\teval-rmse:0.93117\n",
      "[65]\ttrain-rmse:0.63138\teval-rmse:0.93111\n",
      "[66]\ttrain-rmse:0.63124\teval-rmse:0.93104\n",
      "[67]\ttrain-rmse:0.63108\teval-rmse:0.93113\n",
      "[68]\ttrain-rmse:0.63082\teval-rmse:0.93116\n",
      "[69]\ttrain-rmse:0.63055\teval-rmse:0.93104\n",
      "[70]\ttrain-rmse:0.63031\teval-rmse:0.93108\n",
      "[71]\ttrain-rmse:0.63017\teval-rmse:0.93100\n",
      "[72]\ttrain-rmse:0.62999\teval-rmse:0.93104\n",
      "[73]\ttrain-rmse:0.62977\teval-rmse:0.93101\n",
      "[74]\ttrain-rmse:0.62948\teval-rmse:0.93085\n",
      "[75]\ttrain-rmse:0.62928\teval-rmse:0.93106\n",
      "[76]\ttrain-rmse:0.62916\teval-rmse:0.93127\n",
      "[77]\ttrain-rmse:0.62897\teval-rmse:0.93123\n",
      "[78]\ttrain-rmse:0.62879\teval-rmse:0.93123\n",
      "[79]\ttrain-rmse:0.62853\teval-rmse:0.93114\n",
      "[80]\ttrain-rmse:0.62839\teval-rmse:0.93109\n",
      "[81]\ttrain-rmse:0.62812\teval-rmse:0.93096\n",
      "[82]\ttrain-rmse:0.62801\teval-rmse:0.93097\n",
      "[83]\ttrain-rmse:0.62783\teval-rmse:0.93098\n",
      "[84]\ttrain-rmse:0.62760\teval-rmse:0.93084\n",
      "[85]\ttrain-rmse:0.62738\teval-rmse:0.93064\n",
      "[86]\ttrain-rmse:0.62720\teval-rmse:0.93079\n",
      "[87]\ttrain-rmse:0.62694\teval-rmse:0.93070\n",
      "[88]\ttrain-rmse:0.62682\teval-rmse:0.93088\n",
      "[89]\ttrain-rmse:0.62670\teval-rmse:0.93099\n",
      "[90]\ttrain-rmse:0.62648\teval-rmse:0.93113\n",
      "[91]\ttrain-rmse:0.62631\teval-rmse:0.93110\n",
      "[92]\ttrain-rmse:0.62611\teval-rmse:0.93147\n",
      "[93]\ttrain-rmse:0.62581\teval-rmse:0.93144\n",
      "[94]\ttrain-rmse:0.62556\teval-rmse:0.93163\n",
      "[95]\ttrain-rmse:0.62540\teval-rmse:0.93159\n",
      "[96]\ttrain-rmse:0.62525\teval-rmse:0.93152\n",
      "[97]\ttrain-rmse:0.62503\teval-rmse:0.93147\n",
      "[98]\ttrain-rmse:0.62490\teval-rmse:0.93139\n",
      "[99]\ttrain-rmse:0.62463\teval-rmse:0.93146\n",
      "[100]\ttrain-rmse:0.62444\teval-rmse:0.93143\n",
      "[101]\ttrain-rmse:0.62430\teval-rmse:0.93136\n",
      "[102]\ttrain-rmse:0.62419\teval-rmse:0.93141\n",
      "[103]\ttrain-rmse:0.62410\teval-rmse:0.93141\n",
      "[104]\ttrain-rmse:0.62387\teval-rmse:0.93115\n",
      "[105]\ttrain-rmse:0.62372\teval-rmse:0.93116\n",
      "[106]\ttrain-rmse:0.62359\teval-rmse:0.93119\n",
      "[107]\ttrain-rmse:0.62349\teval-rmse:0.93115\n",
      "[108]\ttrain-rmse:0.62340\teval-rmse:0.93121\n",
      "[109]\ttrain-rmse:0.62322\teval-rmse:0.93111\n",
      "[110]\ttrain-rmse:0.62297\teval-rmse:0.93106\n",
      "[111]\ttrain-rmse:0.62280\teval-rmse:0.93107\n",
      "[112]\ttrain-rmse:0.62254\teval-rmse:0.93106\n",
      "[113]\ttrain-rmse:0.62241\teval-rmse:0.93116\n",
      "[114]\ttrain-rmse:0.62227\teval-rmse:0.93099\n",
      "[115]\ttrain-rmse:0.62203\teval-rmse:0.93088\n",
      "[116]\ttrain-rmse:0.62188\teval-rmse:0.93085\n",
      "[117]\ttrain-rmse:0.62175\teval-rmse:0.93081\n",
      "[118]\ttrain-rmse:0.62158\teval-rmse:0.93075\n",
      "[119]\ttrain-rmse:0.62144\teval-rmse:0.93068\n",
      "[120]\ttrain-rmse:0.62135\teval-rmse:0.93070\n",
      "[121]\ttrain-rmse:0.62112\teval-rmse:0.93073\n",
      "[122]\ttrain-rmse:0.62091\teval-rmse:0.93071\n",
      "[123]\ttrain-rmse:0.62074\teval-rmse:0.93073\n",
      "[124]\ttrain-rmse:0.62065\teval-rmse:0.93075\n",
      "[125]\ttrain-rmse:0.62053\teval-rmse:0.93078\n",
      "[126]\ttrain-rmse:0.62038\teval-rmse:0.93075\n",
      "[127]\ttrain-rmse:0.62023\teval-rmse:0.93083\n",
      "[128]\ttrain-rmse:0.62004\teval-rmse:0.93092\n",
      "[129]\ttrain-rmse:0.61993\teval-rmse:0.93083\n",
      "[130]\ttrain-rmse:0.61976\teval-rmse:0.93072\n",
      "[131]\ttrain-rmse:0.61968\teval-rmse:0.93081\n",
      "[132]\ttrain-rmse:0.61949\teval-rmse:0.93089\n",
      "[133]\ttrain-rmse:0.61935\teval-rmse:0.93108\n",
      "[134]\ttrain-rmse:0.61918\teval-rmse:0.93092\n"
     ]
    }
   ],
   "source": [
    "# Train the model with early stopping\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_round,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,  # Stop after 50 rounds of no improvement\n",
    "    verbose_eval=True  # Print evaluation results during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 85\n"
     ]
    }
   ],
   "source": [
    "# after training, get the best iteration\n",
    "best_iteration = bst.best_iteration\n",
    "print(f\"best iteration: {best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evalute on test set (seen test + unseen test)\n",
      "test_mse: 1.0201\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "print(\"evalute on test set (seen test + unseen test)\")\n",
    "X_test, y_test = get_all_data(test_file)\n",
    "# convert to DMatrix format\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"test_mse: {test_mse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
