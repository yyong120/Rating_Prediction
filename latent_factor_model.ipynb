{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_set.csv'\n",
    "valid_file = 'valid_set.csv'\n",
    "seen_test_file = 'seen_test_set.csv'\n",
    "unseen_test_file = 'unseen_test_set.csv'\n",
    "test_file = 'test_set.csv'\n",
    "\n",
    "def get_all_u_i_r(file_name):\n",
    "    df = pd.read_csv(file_name, sep=',')\n",
    "    u_i_r_list = []\n",
    "\n",
    "    # iterate through the whole dataset\n",
    "    for _, row in df.iterrows():\n",
    "        item = int(row['item_idx'])\n",
    "        user = int(row['user_idx'])\n",
    "        rating = row['rating']\n",
    "        u_i_r_list.append([user, item, rating])\n",
    "    \n",
    "    return u_i_r_list\n",
    "\n",
    "train_u_i_r = get_all_u_i_r(train_file)\n",
    "\n",
    "# valid_u_i_r = get_all_u_i_r(valid_file)\n",
    "# valid_u = [u for u, i, r in valid_u_i_r]\n",
    "# valid_i = [i for u, i, r in valid_u_i_r]\n",
    "# valid_r = [r for u, i, r in valid_u_i_r]\n",
    "\n",
    "# seen_test_u_i_r = get_all_u_i_r(seen_test_file)\n",
    "# seen_test_u_i = [[u, i] for u, i, r in seen_test_u_i_r]\n",
    "\n",
    "# unseen_test_u_i_r = get_all_u_i_r(unseen_test_file)\n",
    "# unseen_test_u_i = [[u, i] for u, i, r in unseen_test_u_i_r]\n",
    "\n",
    "# test_u_i_r = get_all_u_i_r(test_file)\n",
    "# test_u_i = [[u, i] for u, i, r in test_u_i_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44683\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "# calculate global average rating on train+valid\n",
    "avg_rating = np.mean([r for u, i, r in train_u_i_r] + \n",
    "                                 [r for u, i, r in valid_u_i_r]\n",
    "                                 )\n",
    "\n",
    "# get the number of users and items in train+valid\n",
    "n_users = max(max([u for u, i, r in train_u_i_r]), max([u for u, i, r in valid_u_i_r]))\n",
    "n_items = max(max([i for u, i, r in train_u_i_r]), max([i for u, i, r in valid_u_i_r]))\n",
    "print(n_users)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "class U_I_R_Dataset(Dataset):\n",
    "    def __init__(self, u_i_r_list):\n",
    "        self.u_i_r_list = u_i_r_list  # List of [user_idx, item_idx, rating]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.u_i_r_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        u, i, r = self.u_i_r_list[idx]\n",
    "        return torch.tensor(u, dtype=torch.long), torch.tensor(i, dtype=torch.long), torch.tensor(r, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable parameters\n",
    "K = 5   # dimension of gamma_u / gamma_i\n",
    "alpha_init = avg_rating # maybe no need to tune this\n",
    "lamb_beta_u = 0.01\n",
    "lamb_beta_i = 0.01\n",
    "lamb_gamma_u = 0.01\n",
    "lamb_gamma_i = 0.01\n",
    "learning_rate = 0.01\n",
    "batch_size = 1024\n",
    "max_train_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and dataloader\n",
    "train_dataset = U_I_R_Dataset(train_u_i_r)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModel(nn.Module):\n",
    "    def __init__(self, alpha_init, K, lamb_beta_u, lamb_beta_i, lamb_gamma_u, lamb_gamma_i, num_users, num_items):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "\n",
    "        # Initialize scalar average rating\n",
    "        self.alpha = nn.Parameter(torch.tensor(alpha_init, dtype=torch.float32))\n",
    "\n",
    "        # Bias terms for users and items\n",
    "        # user/item idx = 0 means unseen user/item\n",
    "        self.betaU = nn.Embedding(num_users+1, 1, padding_idx=0)\n",
    "        self.betaI = nn.Embedding(num_items+1, 1, padding_idx=0)\n",
    "\n",
    "        # Latent factors for users and items\n",
    "        self.gammaU = nn.Embedding(num_users+1, K, padding_idx=0)\n",
    "        self.gammaI = nn.Embedding(num_items+1, K, padding_idx=0)\n",
    "        self.lamb_beta_u = lamb_beta_u\n",
    "        self.lamb_beta_i = lamb_beta_i\n",
    "        self.lamb_gamma_u = lamb_gamma_u\n",
    "        self.lamb_gamma_i = lamb_gamma_i\n",
    "\n",
    "        # Initialize embeddings with small random values\n",
    "        # If training doesn't converge, try other initialization strategies, e.g. initialize all parameters to 0\n",
    "        nn.init.normal_(self.betaU.weight, mean=0.0, std=0.001)\n",
    "        nn.init.normal_(self.betaI.weight, mean=0.0, std=0.001)\n",
    "        nn.init.normal_(self.gammaU.weight, mean=0.0, std=0.001)\n",
    "        nn.init.normal_(self.gammaI.weight, mean=0.0, std=0.001)\n",
    "\n",
    "    # u / i should have the shape of (b,)\n",
    "    def predict(self, u, i):\n",
    "        beta_u = self.betaU(u).squeeze()    # (b,)\n",
    "        beta_i = self.betaI(i).squeeze()    # (b,)\n",
    "        gamma_u = self.gammaU(u)            # (b, K)\n",
    "        gamma_i = self.gammaI(i)            # (b, K)\n",
    "        p = self.alpha + beta_u + beta_i + torch.sum(gamma_u * gamma_i, dim=-1)\n",
    "        return p    # (b,)\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return (\n",
    "            self.lamb_beta_u * torch.sum(self.betaU.weight**2) +\n",
    "            self.lamb_beta_i * torch.sum(self.betaI.weight**2) +\n",
    "            self.lamb_gamma_u * torch.sum(self.gammaU.weight**2) +\n",
    "            self.lamb_gamma_i * torch.sum(self.gammaI.weight**2)\n",
    "        )\n",
    "\n",
    "    # Loss\n",
    "    # u, i, r should have the shape of (b,)\n",
    "    def forward(self, u, i, r):\n",
    "        pred = self.predict(u, i)\n",
    "        # r = torch.tensor(r, dtype=torch.float32)\n",
    "        return torch.nn.functional.mse_loss(pred, r, reduction='mean')\n",
    "\n",
    "\n",
    "# evaluate on valid/test set\n",
    "# u, i should be torch.long tensors with the shape of (b,)\n",
    "# r should be torch.float32 tensors with the shape of (b,)\n",
    "def evaluate(model, u, i, r):\n",
    "    model.eval()\n",
    "    pred = model.predict(u, i)  # (b,)\n",
    "\n",
    "    model.train()\n",
    "    return torch.nn.functional.mse_loss(pred, r, reduction='mean').item()\n",
    "\n",
    "\n",
    "# training function\n",
    "# early stop if mse of valid set starts to increase\n",
    "def training_step(model, dataloader, optimizer, valid_u, valid_i, valid_r, pre_valid_mse=None):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    early_stop = False\n",
    "\n",
    "    for u, i, r in dataloader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Forward pass: calculate the predicted ratings\n",
    "        loss = model(u, i, r)  # Model forward pass\n",
    "        loss += model.reg()  # Add regularization loss\n",
    "        \n",
    "        loss.backward()  # Backward pass: compute gradients\n",
    "        optimizer.step()  # Optimizer step: update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # evaluate on valid set to check if we need to early stop\n",
    "        valid_mse = evaluate(model, valid_u, valid_i, valid_r)\n",
    "        # print(f\"valid_mse: {valid_mse:.4f}\")\n",
    "        if (pre_valid_mse is not None and pre_valid_mse < valid_mse) or np.isnan(valid_mse):\n",
    "            early_stop = True\n",
    "            break\n",
    "        pre_valid_mse = valid_mse\n",
    "\n",
    "    # Return average loss per batch, early stop, valid_mse\n",
    "    return total_loss / len(dataloader), early_stop, valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at epoch 1, valid_mse = 1.1493\n"
     ]
    }
   ],
   "source": [
    "# convert valid set to tensors\n",
    "valid_u_i_r = get_all_u_i_r(valid_file)\n",
    "valid_u = [u for u, i, r in valid_u_i_r]\n",
    "valid_i = [i for u, i, r in valid_u_i_r]\n",
    "valid_r = [r for u, i, r in valid_u_i_r]\n",
    "\n",
    "valid_u = torch.tensor(valid_u).to(torch.long)\n",
    "valid_i = torch.tensor(valid_i).to(torch.long)\n",
    "valid_r = torch.tensor(valid_r).to(torch.float32)\n",
    "\n",
    "# Initialize model\n",
    "modelLFM = LatentFactorModel(alpha_init, K, lamb_beta_u, lamb_beta_i, lamb_gamma_u, lamb_gamma_i, n_users, n_items)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(modelLFM.parameters(), lr=learning_rate)\n",
    "\n",
    "# train loop\n",
    "pre_valid_mse = None\n",
    "for epoch in range(max_train_step):\n",
    "    avg_loss, early_stop, valid_mse = training_step(modelLFM, train_dataloader, optimizer, valid_u, valid_i, valid_r, pre_valid_mse)\n",
    "    if early_stop:\n",
    "        print(f\"Early stop at epoch {epoch + 1}, valid_mse = {valid_mse:.4f}\")\n",
    "        break\n",
    "    if epoch % 10 == 9:\n",
    "        print(f\"Epoch {epoch + 1}, average loss = {avg_loss:.4f}\")\n",
    "    pre_valid_mse = valid_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evalute on test set (seen test + unseen test)\n",
      "test_mse: 1.1274\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "print(\"evalute on test set (seen test + unseen test)\")\n",
    "test_u_i_r = get_all_u_i_r(test_file)\n",
    "test_u = [u for u, i, r in test_u_i_r]\n",
    "test_i = [i for u, i, r in test_u_i_r]\n",
    "test_r = [r for u, i, r in test_u_i_r]\n",
    "\n",
    "test_u = torch.tensor(test_u).to(torch.long)\n",
    "test_i = torch.tensor(test_i).to(torch.long)\n",
    "test_r = torch.tensor(test_r).to(torch.float32)\n",
    "\n",
    "test_mse = evaluate(modelLFM, test_u, test_i, test_r)\n",
    "print(f\"test_mse: {test_mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
